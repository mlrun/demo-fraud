{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Application Pipeline\n",
    "\n",
    "In this example, we define an application pipeline that accepts a user request, enriches the request with real-time features from the feature store, and feeds the features into a three-legged ensemble that uses the newly trained models.\n",
    "\n",
    "You would typically need to implement and deploy multiple microservices and comâ€ plex logic to build such an application pipeline. But, with MLRun, you can define it in a few lines of code and deploy it automatically into elastic serverless functions. In addition, the MLRun serving framework will automatically support real-time feature imputing, model monitoring, and so on without requiring extra coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "project = mlrun.load_project(\n",
    "    name=\"fraud-demo\",\n",
    "    context=\"./\",\n",
    "    user_project=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom serving class\n",
    "\n",
    "MLRun has many built-in model-serving classes for different frameworks (Sklearn, Xgboost, PyTorch, TensorFlow, ONNX, Hugging Face models, and so on). You can also build your custom model serving class as demonstrated in Example 7-24. The serving class must support the load() method for loading the model and the predict() method for making a prediction. You can read MLRun documentation to see all the hooks and advanced usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cloudpickle import load\n",
    "from mlrun.serving.v2_serving import V2ModelServer\n",
    "\n",
    "class ClassifierModel(V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        print(f\"Input -> {body['inputs']}\")\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Application Pipeline with Enrichment and Ensemble\n",
    "\n",
    "MLRun serving can produce managed real-time serverless pipelines from various tasks, including MLRun models or standard model files. The pipelines use the Nuclio real-time serverless engine, which can be deployed anywhere. Nuclio is a high-performance open-source serverless framework focused on data, I/O, and compute-intensive workloads.\n",
    "\n",
    "The EnrichmentVotingEnsemble router class auto-enriches the request with data from the feature store. The router input accepts a list of inference requests (each request can be a dict or list of incoming features/keys). It enriches the request with data from the specified feature vector (feature_vector_uri), forwards the vector to one or more models in an ensemble, and returns an aggregated prediction value (for example, the average result across the three models).\n",
    "The features can often have null values (None, NaN, Inf). The Enrichment_ routers can substitute the null value with fixed or statistical value per fea ture. This is done through the `impute_policy` parameter, which accepts the impute policy per feature (where * is used to specify the default). The value can be a fixed number for constants or $mean, $max, $min, $std, $count for statistical values to substitute the value with the equivalent feature stats (taken from the feature store).\n",
    "The code in Example 7-24 defines a new serving function with the ClassifierModel class code (in serving.py) and a router topology (using the EnrichmentVotingEnsem ble router class) with three child models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transaction_fraud_rf',\n",
       "  {'tree': '4133f7a9627d4b048e7feddbdea5f3e3',\n",
       "   'project': 'fraud-demo-jovyan',\n",
       "   'labels': {'workflow-id': '4133f7a9627d4b048e7feddbdea5f3e3',\n",
       "    'framework': 'sklearn'},\n",
       "   'tag': 'latest',\n",
       "   'updated': '2025-01-06 11:44:42.239097+00:00',\n",
       "   'key': 'model',\n",
       "   'hash': '1ea6d690b6986ebb4dd68b454886f84fd06c749d',\n",
       "   'iter': 1}),\n",
       " ('transaction_fraud_xgboost',\n",
       "  {'tree': '4133f7a9627d4b048e7feddbdea5f3e3',\n",
       "   'project': 'fraud-demo-jovyan',\n",
       "   'labels': {'workflow-id': '4133f7a9627d4b048e7feddbdea5f3e3',\n",
       "    'framework': 'sklearn'},\n",
       "   'tag': 'latest',\n",
       "   'updated': '2025-01-06 11:44:39.610602+00:00',\n",
       "   'key': 'model',\n",
       "   'hash': '76d747673d144065859bfbe1a46dff2fdd6e9a2d',\n",
       "   'iter': 2}),\n",
       " ('transaction_fraud_adaboost',\n",
       "  {'tree': '4133f7a9627d4b048e7feddbdea5f3e3',\n",
       "   'project': 'fraud-demo-jovyan',\n",
       "   'labels': {'workflow-id': '4133f7a9627d4b048e7feddbdea5f3e3',\n",
       "    'framework': 'sklearn'},\n",
       "   'tag': 'latest',\n",
       "   'updated': '2025-01-06 11:44:40.787779+00:00',\n",
       "   'key': 'model',\n",
       "   'hash': '90376066db6495b3495c46b65a46d42ba908a309',\n",
       "   'iter': 3})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m.spec.db_key, m.metadata.to_dict()) for m in project.list_models('', tag='latest')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"634pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 634.43 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-192 630.43,-192 630.43,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"290.23,-152.05 292,-152.15 293.76,-152.3 295.49,-152.49 297.19,-152.74 298.85,-153.03 300.47,-153.36 302.03,-153.75 303.53,-154.18 304.97,-154.65 306.34,-155.16 307.64,-155.71 308.86,-156.31 310,-156.94 311.05,-157.61 312.01,-158.31 312.89,-159.04 313.67,-159.8 314.36,-160.59 314.95,-161.41 315.45,-162.25 315.85,-163.11 316.16,-163.99 316.38,-164.89 316.5,-165.8 316.53,-166.72 316.48,-167.65 316.34,-168.59 316.11,-169.53 315.81,-170.47 315.43,-171.41 314.98,-172.35 314.46,-173.28 313.88,-174.2 313.23,-175.11 312.52,-176.01 311.77,-176.89 310.96,-177.75 310.1,-178.59 309.21,-179.41 308.27,-180.2 307.31,-180.96 306.31,-181.69 305.28,-182.39 304.23,-183.06 303.15,-183.69 302.06,-184.29 300.95,-184.84 299.82,-185.35 298.68,-185.82 297.54,-186.25 296.38,-186.64 295.21,-186.97 294.04,-187.26 292.87,-187.51 291.69,-187.7 290.51,-187.85 289.32,-187.95 288.14,-188 286.95,-188 285.76,-187.95 284.58,-187.85 283.4,-187.7 282.22,-187.51 281.04,-187.26 279.87,-186.97 278.71,-186.64 277.55,-186.25 276.4,-185.82 275.26,-185.35 274.14,-184.84 273.03,-184.29 271.93,-183.69 270.86,-183.06 269.81,-182.39 268.78,-181.69 267.78,-180.96 266.81,-180.2 265.88,-179.41 264.98,-178.59 264.13,-177.75 263.32,-176.89 262.56,-176.01 261.86,-175.11 261.21,-174.2 260.62,-173.28 260.1,-172.35 259.65,-171.41 259.27,-170.47 258.97,-169.53 258.75,-168.59 258.61,-167.65 258.55,-166.72 258.59,-165.8 258.71,-164.89 258.93,-163.99 259.23,-163.11 259.64,-162.25 260.14,-161.41 260.73,-160.59 261.42,-159.8 262.2,-159.04 263.07,-158.31 264.04,-157.61 265.09,-156.94 266.23,-156.31 267.45,-155.71 268.74,-155.16 270.11,-154.65 271.55,-154.18 273.06,-153.75 274.62,-153.36 276.23,-153.03 277.89,-152.74 279.59,-152.49 281.33,-152.3 283.08,-152.15 284.86,-152.05 286.65,-152 288.44,-152 290.23,-152.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.54\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"314.54,-86.54 314.54,-101.46 298.73,-112 276.36,-112 260.54,-101.46 260.54,-86.54 276.36,-76 298.73,-76 314.54,-86.54\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"318.54,-84.4 318.54,-103.6 299.94,-116 275.15,-116 256.54,-103.6 256.54,-84.4 275.15,-72 299.94,-72 318.54,-84.4\"/>\n",
       "</g>\n",
       "<!-- _start&#45;&gt; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M287.54,-151.84C287.54,-144.16 287.54,-134.88 287.54,-126.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"291.04,-126.03 287.54,-116.03 284.04,-126.03 291.04,-126.03\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_rf -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>transaction_fraud_rf</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"82.54\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"82.54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_rf</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_rf -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_rf</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.04,-82.71C226.51,-70.97 172.71,-51.55 133.04,-37.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.13,-33.9 123.53,-33.8 131.75,-40.48 134.13,-33.9\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_xgboost -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>transaction_fraud_xgboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"287.54\" cy=\"-18\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_xgboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_xgboost -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_xgboost</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M287.54,-71.99C287.54,-64.06 287.54,-54.91 287.54,-46.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"291.04,-46.31 287.54,-36.31 284.04,-46.31 291.04,-46.31\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_adaboost -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>transaction_fraud_adaboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"518.54\" cy=\"-18\" rx=\"107.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"518.54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_adaboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_adaboost -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_adaboost</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M317.27,-83.48C353.48,-71.88 415.47,-52.02 461.11,-37.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.42,-40.65 470.88,-34.27 460.28,-33.99 462.42,-40.65\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7d86fcac5ca0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the serving function from your code above\n",
    "serving_fn = project.set_function('src/serving.py', name='test-function',\n",
    "                                  image=\"mlrun/mlrun\", kind=\"serving\")\n",
    "serving_fn.set_topology(\n",
    "    \"router\",\n",
    "    mlrun.serving.routers.EnrichmentVotingEnsemble(\n",
    "        feature_vector_uri=\"short\",\n",
    "        impute_policy={\"*\": \"$mean\"}),\n",
    ")\n",
    "# add the 3 trained models to the Ensemble\n",
    "for model in project.list_models('', tag='latest'):\n",
    "    name = model.spec.db_key\n",
    "    serving_fn.add_model(name, class_name=\"ClassifierModel\", model_path=model.uri)\n",
    "# Plot the ensemble configuration\n",
    "serving_fn.spec.graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Application Pipeline Locally\n",
    "\n",
    "Before deploying the serving function, you can test it in the current notebook and check the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-01-06 12:27:04,235 [info] model transaction_fraud_rf was loaded\n",
      "> 2025-01-06 12:27:04,246 [info] model transaction_fraud_xgboost was loaded\n",
      "> 2025-01-06 12:27:04,257 [info] model transaction_fraud_adaboost was loaded\n"
     ]
    }
   ],
   "source": [
    "# Create a mock server from the serving function\n",
    "local_server = serving_fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input -> [[82.395271, 175.21864100000002]]\n",
      "Input -> [[82.395271, 175.21864100000002]]\n",
      "Input -> [[82.395271, 175.21864100000002]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '9b11acab9aa548b69658ce4cdaea4ee6',\n",
       " 'model_name': 'VotingEnsemble',\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "\n",
    "# Send your sample ID for prediction\n",
    "local_server.test(path='/v2/models/infer',\n",
    "            body={'inputs': [[sample_id]]})\n",
    "\n",
    "# notice the input vector is printed 3 times (once per child model) and is enriched with data from the feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accessing the real-time feature vector directly\n",
    "\n",
    "If you would like to access the real-time features directly from your application instead of using the EnrichmentVotingEnsemble, you can call the feature store `get_online_feature_service()` method. This method is used internally in the EnrichmentVotingEnsemble router class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'amount_max_2h': 82.395271, 'amount_sum_2h': 175.21864100000002}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlrun.feature_store as fs\n",
    "\n",
    "# Create the online feature service\n",
    "svc = fs.get_feature_vector('short:latest').get_online_feature_service(impute_policy={\"*\": \"$mean\"})\n",
    "\n",
    "# Get sample feature vector\n",
    "sample_fv = svc.get([{'source': sample_id}])\n",
    "sample_fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the function on the Kubernetes cluster\n",
    "\n",
    "You can now deploy the function. Once deployed, you get a function with http trigger that can be called from other locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On community edition, set Redis credentials.\n",
    "\n",
    "import os\n",
    "redis_host = os.getenv(\"REDIS_MASTER_SERVICE_HOST\", \"100.98.222.55\")\n",
    "redis_port = int(os.getenv(\"REDIS_REPLICAS_SERVICE_PORT\", 30051))\n",
    "\n",
    "redis_uri = f\"redis://{redis_host}:{redis_port}\" \n",
    "if mlrun.mlconf.is_ce_mode():\n",
    "    serving_fn.set_envs({'REDIS_URI': redis_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-01-06 12:27:14,216 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n",
      "> 2025-01-06 12:27:14,220 [info] Starting remote function deploy\n",
      "2025-01-06 12:27:15  (info) Deploying function\n",
      "2025-01-06 12:27:15  (info) Building\n",
      "2025-01-06 12:27:16  (info) Staging files and preparing base images\n",
      "2025-01-06 12:27:16  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2025-01-06 12:27:16  (info) Building processor image\n",
      "2025-01-06 12:30:51  (info) Build complete\n",
      "2025-01-06 12:31:05  (info) Function deploy complete\n",
      "> 2025-01-06 12:31:07,818 [info] Successfully deployed function: {\"external_invocation_urls\":[\"localhost:31802\"],\"internal_invocation_urls\":[\"nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://localhost:31802'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Deploy the serving function\n",
    "serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server\n",
    "\n",
    "You can test the serving function and examine the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-01-06 12:31:07,844 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '27f171e2-3003-4337-8994-89ae9f6a5bc6',\n",
       " 'model_name': 'VotingEnsemble',\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "\n",
    "model_inference_path = '/v2/models/infer'\n",
    "\n",
    "# Send your sample ID for prediction\n",
    "serving_fn.invoke(path='/v2/models/infer',\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly query the feature store values, which are used in the enrichment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = mlrun.get_dataitem(mlrun.get_sample_path(\"data/fraud-demo-mlrun-fs-docs/data.csv\")).as_df()\n",
    "\n",
    "# use only first 10k\n",
    "data = data.sort_values(by='source', axis=0)[:10000]\n",
    "\n",
    "# keys\n",
    "sample_ids = data['source'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-01-06 12:31:27,627 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '13db11d0-6825-4a1f-95d2-6df3c2f80b8a', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:28,430 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '9bab2f7c-df4b-4f9d-9c35-c9ba4389cf98', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:30,068 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '09f1bb33-eb4d-4e58-adea-2f51926890af', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:30,571 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '7f699a6a-8e5d-4aa7-a845-1cc6828562e0', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:31,546 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '13f9e905-5f65-4d12-9b36-139e61544810', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:32,292 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '4fe4f685-fc1b-4d45-95df-307f918cee3c', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:33,773 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'e3f1c895-d2ad-45dd-9a69-331fca3155b5', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:35,420 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '5fd86a56-88b9-4f1b-95c5-bae45f9e1f1f', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:36,891 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'fb73baa7-a66c-4765-87c0-d29a4df439a8', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2025-01-06 12:31:37,819 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-jovyan-test-function.mlrun.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'fd15c6bd-002f-49de-ad53-aa21bbc17226', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n"
     ]
    }
   ],
   "source": [
    "from random import choice, uniform\n",
    "from time import sleep\n",
    "\n",
    "# Sending random requests\n",
    "for _ in range(10):\n",
    "    data_point = choice(sample_ids)\n",
    "    try:\n",
    "        resp = serving_fn.invoke(path=model_inference_path, body={'inputs': [[data_point]]})\n",
    "        print(resp)\n",
    "        sleep(uniform(0.2, 1.7))\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Done!\n",
    "\n",
    "You've completed the fraud-detection demo. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
