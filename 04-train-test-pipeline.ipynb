{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validation Pipeline\n",
    "Now that you have created features, you can use them to train one or more models. In this section, you will generate feature vectors with multiple features from one or more feature sets and feed them into an automated ML training and testing pipeline to create high-quality models.\n",
    "\n",
    "The ML pipeline can be triggered and tracked manually during the interactive develâ€ opment, or it can be saved (into Git) and be executed automatically on a given schedule or as a reaction to different events (such as code modification, CI/CD, data changes, model drift, and so on). See [MLRun project and CI/CD documentation](https://docs.mlrun.org/en/stable/projects/project.html) for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading projects from GIT\n",
    "\n",
    "After you saved your project and its elements (functions, workflows, artifacts, etc.) you can commit all your changes to a \n",
    "GIT repository. This can be done using standard GIT tools or using MLRun `project` methods such as `pull`, `push`, \n",
    "`remote`, which calls the Git API for you.\n",
    "\n",
    "Projects can then be loaded from Git using MLRun `load_project` method, for example: \n",
    "\n",
    "    project = mlrun.load_project(\"./myproj\", \"git://github.com/mlrun/project-demo.git\", name=project_name)\n",
    "    \n",
    "or using MLRun CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-demo.git\" ./myproj\n",
    "    \n",
    "Projects can be loaded or created by using MLRun `get_or_create_project` method.\n",
    "    \n",
    "Read [CI/CD integration](../../projects/ci-integration.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-12-06 08:52:19,869 [info] Project loaded successfully: {\"project_name\":\"fraud-demo-jovyan\"}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=\"fraud-demo\",\n",
    "    context=\"./\",\n",
    "    user_project=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Evaluating a Feature Vector\n",
    "\n",
    "Models are trained with multiple features, which can arrive from different feature sets and be collected into training (feature) vectors. Feature stores know how to correctly combine the features into a vector by implementing smart JOINs and assessing the time dimension (time traveling).\n",
    "To define a feature vector, you need to specify a name, the list of features it contains, the target features (labels), and other optional parameters. Features are specified as `<FeatureSet>.<Feature> or <FeatureSet>.*`  (all the features in a feature set). The following part demonstrates how to create and use a feature vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the list of features to use\n",
    "features = ['events.*',\n",
    "            'transactions.amount_max_2h', \n",
    "            'transactions.amount_sum_2h', \n",
    "            'transactions.amount_count_2h',\n",
    "            'transactions.amount_avg_2h', \n",
    "            'transactions.amount_max_12h', \n",
    "            'transactions.amount_sum_12h',\n",
    "            'transactions.amount_count_12h', \n",
    "            'transactions.amount_avg_12h', \n",
    "            'transactions.amount_max_24h',\n",
    "            'transactions.amount_sum_24h', \n",
    "            'transactions.amount_count_24h', \n",
    "            'transactions.amount_avg_24h',\n",
    "            'transactions.es_transportation_sum_14d', \n",
    "            'transactions.es_health_sum_14d',\n",
    "            'transactions.es_otherservices_sum_14d', \n",
    "            'transactions.es_food_sum_14d',\n",
    "            'transactions.es_hotelservices_sum_14d', \n",
    "            'transactions.es_barsandrestaurants_sum_14d',\n",
    "            'transactions.es_tech_sum_14d', \n",
    "            'transactions.es_sportsandtoys_sum_14d',\n",
    "            'transactions.es_wellnessandbeauty_sum_14d', \n",
    "            'transactions.es_hyper_sum_14d',\n",
    "            'transactions.es_fashion_sum_14d', \n",
    "            'transactions.es_home_sum_14d', \n",
    "            'transactions.es_travel_sum_14d', \n",
    "            'transactions.es_leisure_sum_14d',\n",
    "            'transactions.gender_F',\n",
    "            'transactions.gender_M',\n",
    "            'transactions.step', \n",
    "            'transactions.amount', \n",
    "            'transactions.timestamp_hour',\n",
    "            'transactions.timestamp_day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature vector name for future reference\n",
    "fv_name = 'transactions-fraud'\n",
    "\n",
    "# Define the feature vector using the feature store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(fv_name, \n",
    "                          features, \n",
    "                          label_feature=\"labels.label\",\n",
    "                          description='Predicting a fraudulent transaction')\n",
    "\n",
    "# Save the feature vector in the feature store\n",
    "transactions_fv.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MLRunNotFoundError",
     "evalue": "there are no offline targets for this feature vector",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMLRunNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransactions_fv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/feature_vector.py:609\u001b[0m, in \u001b[0;36mFeatureVector.to_dataframe\u001b[0;34m(self, df_module, target_name)\u001b[0m\n\u001b[1;32m    607\u001b[0m driver \u001b[38;5;241m=\u001b[39m get_offline_target(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39mtarget_name)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m driver:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m mlrun\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mMLRunNotFoundError(\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere are no offline targets for this feature vector\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    611\u001b[0m     )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mas_df(df_module\u001b[38;5;241m=\u001b[39mdf_module)\n",
      "\u001b[0;31mMLRunNotFoundError\u001b[0m: there are no offline targets for this feature vector"
     ]
    }
   ],
   "source": [
    "transactions_fv.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(transactions_fv.save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test get_offline_features function\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlrun\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtargets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParquetTarget\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtransactions_fv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_offline_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/feature_vector.py:810\u001b[0m, in \u001b[0;36mFeatureVector.get_offline_features\u001b[0;34m(self, entity_rows, entity_timestamp_column, target, run_config, drop_columns, start_time, end_time, with_indexes, update_stats, engine, engine_args, query, order_by, spark_service, timestamp_for_filtering, additional_filters)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_offline_features\u001b[39m(\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    729\u001b[0m     entity_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     additional_filters: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m ):\n\u001b[1;32m    746\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"retrieve offline feature vector results\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m    specify a feature vector object/uri and retrieve the desired features, their metadata\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmlrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_offline_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentity_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentity_timestamp_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdate_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspark_service\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_for_filtering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/api.py:274\u001b[0m, in \u001b[0;36m_get_offline_features\u001b[0;34m(feature_vector, entity_rows, entity_timestamp_column, target, run_config, drop_columns, start_time, end_time, with_indexes, update_stats, engine, engine_args, query, order_by, spark_service, timestamp_for_filtering, additional_filters)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run_merge_job(\n\u001b[1;32m    254\u001b[0m         feature_vector,\n\u001b[1;32m    255\u001b[0m         target,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m         additional_filters\u001b[38;5;241m=\u001b[39madditional_filters,\n\u001b[1;32m    271\u001b[0m     )\n\u001b[1;32m    273\u001b[0m merger \u001b[38;5;241m=\u001b[39m merger_engine(feature_vector, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(engine_args \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity_timestamp_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_for_filtering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_for_filtering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/retrieval/base.py:128\u001b[0m, in \u001b[0;36mBaseMerger.start\u001b[0;34m(self, entity_rows, entity_timestamp_column, target, drop_columns, start_time, end_time, timestamp_for_filtering, with_indexes, update_stats, query, order_by, additional_filters)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_time \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m end_time:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# if end_time is not specified set it to now()\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_offline_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity_timestamp_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_set_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_set_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_set_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_set_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_for_filtering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_for_filtering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/retrieval/base.py:258\u001b[0m, in \u001b[0;36mBaseMerger._generate_offline_vector\u001b[0;34m(self, entity_rows, entity_timestamp_column, feature_set_objects, feature_set_fields, start_time, end_time, timestamp_for_filtering, query, order_by, additional_filters)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (start_time \u001b[38;5;129;01mor\u001b[39;00m end_time) \u001b[38;5;129;01mand\u001b[39;00m time_column:\n\u001b[1;32m    256\u001b[0m     timestamp_filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_engine_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m fs_entities_and_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(feature_set\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mentities\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    269\u001b[0m column_names \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fs_entities_and_timestamp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/retrieval/local_merger.py:119\u001b[0m, in \u001b[0;36mLocalFeatureMerger._get_engine_df\u001b[0;34m(self, feature_set, feature_set_name, column_names, start_time, end_time, time_column, additional_filters)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_engine_df\u001b[39m(\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    111\u001b[0m     feature_set,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m     additional_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    118\u001b[0m ):\n\u001b[0;32m--> 119\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    127\u001b[0m         df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/feature_set.py:969\u001b[0m, in \u001b[0;36mFeatureSet.to_dataframe\u001b[0;34m(self, columns, df_module, target_name, start_time, end_time, time_column, additional_filters, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target:\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m mlrun\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mMLRunNotFoundError(\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere are no offline targets for this feature set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 969\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/datastore/targets.py:1019\u001b[0m, in \u001b[0;36mParquetTarget.as_df\u001b[0;34m(self, columns, df_module, entities, start_time, end_time, time_column, additional_filters, **kwargs)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_df\u001b[39m(\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1009\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1017\u001b[0m ):\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"return the target data as dataframe\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1019\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmlrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_target_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_list_filters_to_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m columns:\n\u001b[1;32m   1030\u001b[0m         drop_cols \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/datastore/base.py:608\u001b[0m, in \u001b[0;36mDataItem.as_df\u001b[0;34m(self, columns, df_module, format, time_column, start_time, end_time, additional_filters, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_df\u001b[39m(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    583\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"return a dataframe object (generated from the dataitem).\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    :param columns:     optional, list of columns to select\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m                                https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/datastore/base.py:378\u001b[0m, in \u001b[0;36mDataStore.as_df\u001b[0;34m(self, url, subpath, columns, df_module, format, start_time, end_time, time_column, additional_filters, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m storage_options:\n\u001b[1;32m    377\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m--> 378\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     temp_file \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/datastore/base.py:276\u001b[0m, in \u001b[0;36mDataStore._parquet_reader.<locals>.reader\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df_module\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parquet.py:272\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    266\u001b[0m     path,\n\u001b[1;32m    267\u001b[0m     filesystem,\n\u001b[1;32m    268\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    269\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/parquet/core.py:1776\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1771\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated as of pyarrow 15.0.0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1773\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1776\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/parquet/core.py:1354\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partitioning \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1351\u001b[0m     partitioning \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mHivePartitioning\u001b[38;5;241m.\u001b[39mdiscover(\n\u001b[1;32m   1352\u001b[0m         infer_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/dataset.py:782\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    771\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    772\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    773\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes\n\u001b[1;32m    779\u001b[0m )\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[0;32m--> 782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/dataset.py:465\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    463\u001b[0m     fs, paths_or_selector \u001b[38;5;241m=\u001b[39m _ensure_multiple_sources(source, filesystem)\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     fs, paths_or_selector \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_single_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m options \u001b[38;5;241m=\u001b[39m FileSystemFactoryOptions(\n\u001b[1;32m    468\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[1;32m    469\u001b[0m     partition_base_dir\u001b[38;5;241m=\u001b[39mpartition_base_dir,\n\u001b[1;32m    470\u001b[0m     exclude_invalid_files\u001b[38;5;241m=\u001b[39mexclude_invalid_files,\n\u001b[1;32m    471\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mselector_ignore_prefixes\n\u001b[1;32m    472\u001b[0m )\n\u001b[1;32m    473\u001b[0m factory \u001b[38;5;241m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/dataset.py:441\u001b[0m, in \u001b[0;36m_ensure_single_source\u001b[0;34m(path, filesystem)\u001b[0m\n\u001b[1;32m    439\u001b[0m     paths_or_selector \u001b[38;5;241m=\u001b[39m [path]\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filesystem, paths_or_selector\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760"
     ]
    }
   ],
   "source": [
    "# test get_offline_features function\n",
    "\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "data = transactions_fv.get_offline_features(target=ParquetTarget())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have defined the feature vector, you can use `get_offline_features()` to generate the vector dataset and return it as a dataframe or materialize it into a file (CSV or Parquet). The next part demonstrates how to retrieve a vector, materialize it, and view its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running an Automated Training and Validation Pipeline\n",
    "\n",
    "MLRun allows the building of distributed ML pipelines that can handle data processing, automated feature selection, training, optimization, testing, deployments, and so on. Pipelines are composed of steps that run or deploy custom or library (from the MLRun hub) serverless functions. Pipelines can be run locally (for debugging or small-scale tasks), on a scalable Kubernetes cluster (using Kubeflow), or in a CI/CD system.\n",
    "\n",
    "The example consists of the following pipeline steps (all using pre-defined MLRun hub functions):\n",
    "\n",
    "1. Materialize a feature vector (using `src/get_vector`). \n",
    "2. Select the most optimal features (using `hub://feature_selection`).\n",
    "3. Train the model with multiple algorithms (using `hub://auto_trainer`).\n",
    "4. Evaluate the model (using `hub://auto_trainer`).\n",
    "5. Deploy the model and its application to the test cluster (using `hub://v2_model_server`). The next section will explain the model and application pipeline in detail.\n",
    "\n",
    "Each step can accept the previous stepsâ€™ results or data, and generate results, multiple visual artifacts/charts, versioned data objects, and registered models.\n",
    "\n",
    "We have defined the workflow in [`src/new_train_workflow.py`](./src/new_train_workflow.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running the ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow/pipeline can be executed using the MLRun SDK (`project.run()` method) or using CLI commands (mlrun project), and can run directly from the source repo (GIT). See details in [MLRun Projects and Automation documentation](https://docs.mlrun.org/en/stable/projects/project.html).\n",
    "\n",
    "You can set arguments and destinations for the different artifacts when you run the workflow. The pipeline progress and results are shown in the notebook. Alternatively, you can check the progress, logs, artifacts, and more, in the MLRun UI or the CI/CD system. The next part demonstrates how to run the pipeline with custom arguments using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-12-06 09:19:48,392 [warning] WARNING!, You seem to have uncommitted git changes, use .push()\n",
      "> 2024-12-06 09:19:48,415 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n",
      "> 2024-12-06 09:19:48,419 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n",
      "> 2024-12-06 09:19:48,420 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n",
      "> 2024-12-06 09:19:48,421 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n",
      "> 2024-12-06 09:19:48,423 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Workflow started in project fraud-demo-jovyan id=6ac4fd370f2e427781392765f649d542<div><a href=\"http://localhost:30060/mlrun/projects/fraud-demo-jovyan/jobs\" target=\"_blank\">click here to view progress</a></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-12-06 09:19:48,426 [info] Storing function: {\"db\":null,\"name\":\"get-vector\",\"uid\":\"ec17642e639041f18d1276162f7bb692\"}\n",
      "> 2024-12-06 09:19:48,722 [error] Execution error, Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/runtimes/local.py\", line 506, in exec_from_params\n",
      "    val = mlrun.handler(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/package/__init__.py\", line 140, in wrapper\n",
      "    func_outputs = func(*args, **kwargs)\n",
      "  File \"src/get_vector.py\", line 28, in get_offline_features\n",
      "    data = fv.get_offline_features(target=ParquetTarget())\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/feature_vector.py\", line 810, in get_offline_features\n",
      "    return mlrun.feature_store.api._get_offline_features(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/api.py\", line 274, in _get_offline_features\n",
      "    return merger.start(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/retrieval/base.py\", line 128, in start\n",
      "    return self._generate_offline_vector(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/retrieval/base.py\", line 258, in _generate_offline_vector\n",
      "    df = self._get_engine_df(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/retrieval/local_merger.py\", line 119, in _get_engine_df\n",
      "    df = feature_set.to_dataframe(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/feature_store/feature_set.py\", line 969, in to_dataframe\n",
      "    result = target.as_df(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/datastore/targets.py\", line 1019, in as_df\n",
      "    result = mlrun.get_dataitem(self.get_target_path()).as_df(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/datastore/base.py\", line 608, in as_df\n",
      "    df = self._store.as_df(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/datastore/base.py\", line 378, in as_df\n",
      "    df = reader(url, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/mlrun/datastore/base.py\", line 276, in reader\n",
      "    return df_module.read_parquet(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parquet.py\", line 670, in read_parquet\n",
      "    return impl.read(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parquet.py\", line 272, in read\n",
      "    pa_table = self.api.parquet.read_table(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyarrow/parquet/core.py\", line 1776, in read_table\n",
      "    dataset = ParquetDataset(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyarrow/parquet/core.py\", line 1354, in __init__\n",
      "    self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyarrow/dataset.py\", line 782, in dataset\n",
      "    return _filesystem_dataset(source, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyarrow/dataset.py\", line 465, in _filesystem_dataset\n",
      "    fs, paths_or_selector = _ensure_single_source(source, filesystem)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyarrow/dataset.py\", line 441, in _ensure_single_source\n",
      "    raise FileNotFoundError(path)\n",
      "FileNotFoundError: mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760\n",
      "> 2024-12-06 09:19:48,757 [error] Exec error - mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "\n",
       "  // Get the base URL of the current notebook\n",
       "  var baseUrl = window.location.origin;\n",
       "\n",
       "  // Construct the full URL\n",
       "  var fullUrl = new URL(el.title, baseUrl).href;\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = fullUrl\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (fullUrl.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", fullUrl);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = fullUrl;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>kind</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fraud-demo-jovyan</td>\n",
       "      <td><div title=\"ec17642e639041f18d1276162f7bb692\"><a href=\"http://localhost:30060/mlrun/projects/fraud-demo-jovyan/jobs/monitor/ec17642e639041f18d1276162f7bb692/overview\" target=\"_blank\" >...2f7bb692</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 06 09:19:48</td>\n",
       "      <td><div style=\"color: red;\" title=\"mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760\">error</div></td>\n",
       "      <td>run</td>\n",
       "      <td>get-vector</td>\n",
       "      <td><div class=\"dictlist\">workflow=6ac4fd370f2e427781392765f649d542</div><div class=\"dictlist\">kind=local</div><div class=\"dictlist\">owner=jovyan</div><div class=\"dictlist\">host=mlrun-jupyter-6557dd94b7-mrsm2</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">feature_vector=transactions-fraud</div><div class=\"dictlist\">features=['events.*', 'transactions.amount_max_2h', 'transactions.amount_sum_2h', 'transactions.amount_count_2h', 'transactions.amount_avg_2h', 'transactions.amount_max_12h', 'transactions.amount_sum_12h', 'transactions.amount_count_12h', 'transactions.amount_avg_12h', 'transactions.amount_max_24h', 'transactions.amount_sum_24h', 'transactions.amount_count_24h', 'transactions.amount_avg_24h', 'transactions.es_transportation_sum_14d', 'transactions.es_health_sum_14d', 'transactions.es_otherservices_sum_14d', 'transactions.es_food_sum_14d', 'transactions.es_hotelservices_sum_14d', 'transactions.es_barsandrestaurants_sum_14d', 'transactions.es_tech_sum_14d', 'transactions.es_sportsandtoys_sum_14d', 'transactions.es_wellnessandbeauty_sum_14d', 'transactions.es_hyper_sum_14d', 'transactions.es_fashion_sum_14d', 'transactions.es_home_sum_14d', 'transactions.es_travel_sum_14d', 'transactions.es_leisure_sum_14d', 'transactions.gender_F', 'transactions.gender_M', 'transactions.step', 'transactions.amount', 'transactions.timestamp_hour', 'transactions.timestamp_day_of_week']</div><div class=\"dictlist\">label_feature=labels.label</div><div class=\"dictlist\">target={'name': 'parquet', 'kind': 'parquet'}</div><div class=\"dictlist\">update_stats=True</div></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result5c2da3d7-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result5c2da3d7-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result5c2da3d7\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result5c2da3d7-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> > to track results use the .show() or .logs() methods  or <a href=\"http://localhost:30060/mlrun/projects/fraud-demo-jovyan/jobs/monitor/ec17642e639041f18d1276162f7bb692/overview\" target=\"_blank\">click here</a> to open in UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-12-06 09:19:48,800 [info] Run execution finished: {\"name\":\"get-vector\",\"status\":\"error\"}\n",
      "> 2024-12-06 09:19:48,801 [error] Workflow run failed: {\"exc_info\":[\"Traceback (most recent call last):\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/projects/pipelines.py\\\", line 716, in run\\n    workflow_handler(**workflow_spec.args)\\n\",\"  File \\\"./src/train_workflow.py\\\", line 41, in pipeline\\n    get_vector_run = project.run_function(\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/projects/project.py\\\", line 3473, in run_function\\n    return run_function(\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/projects/operations.py\\\", line 213, in run_function\\n    run_result = function.run(\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/runtimes/base.py\\\", line 403, in run\\n    return launcher.launch(\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/launcher/local.py\\\", line 126, in launch\\n    result = self._execute(\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/launcher/local.py\\\", line 206, in _execute\\n    return self._wrap_run_result(runtime, result, run, err=last_err)\\n\",\"  File \\\"/opt/conda/lib/python3.9/site-packages/mlrun/launcher/base.py\\\", line 415, in _wrap_run_result\\n    raise mlrun.runtimes.utils.RunError(run.error)\\n\",\"mlrun.runtimes.utils.RunError: mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760\\n\"]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "[error] :x: Workflow 6ac4fd370f2e427781392765f649d542 run failed!, error: mlrun/projects/fraud-demo-jovyan/FeatureStore/events/parquet/sets/events/1733393644625_760"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "[info] Pipeline run finished, state=Failed"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={'vector_name':\"transactions-fraud\",\n",
    "               'features': features,\n",
    "                'label_column':\"labels.label\",\n",
    "              }, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-12-05 11:22:55,328 [warning] Function is in the unhealthy state\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no function address first run .deploy()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model_inference_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/v2/models/fraud/infer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Send our sample ID for predcition\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mserving_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_inference_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/runtimes/nuclio/function.py:958\u001b[0m, in \u001b[0;36mRemoteRuntime.invoke\u001b[0;34m(self, path, body, method, headers, dashboard, force_external_address, auth_info, mock, **http_client_kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m state\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    957\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39maddress:\n\u001b[0;32m--> 958\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno function address first run .deploy()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    960\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_invocation_url(path, force_external_address)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: no function address first run .deploy()"
     ]
    }
   ],
   "source": [
    "# Define your serving function\n",
    "serving_fn = project.get_function('serving')\n",
    "\n",
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "model_inference_path = '/v2/models/fraud/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed part 4 - the model training with the feature store.\n",
    "Proceed to [Part 5](06-real-time-serving-pipeline.ipynb) to learn how to deploy real-time application pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
